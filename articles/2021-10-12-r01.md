---
title: "エッジデバイスを用いた監視カメラの開発"
emoji: "📹"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["raspberrypi","docker","python","go","kubernetes"]
published: true
---

RaspberryPiのカメラモジュールを用いて、監視カメラ、およびストリーミングサーバを開発してみました。資材はgithubに配置したため、ここでは考えたことや実装について説明していきたいと思います。

# 要件の整理

本システムについて説明していきます。

## 機材について  

- エッジデバイス
    - 低スペック・複数台を想定
    - カメラを装着している
    - 今回は RaspberryPi 3+ Model A (RAM 512MB) を利用 
- ストリーミングサーバ
    - クラウド環境を想定
    - 今回はkubernetesクラスタを利用
        - RaspberryPi 4 Model B (RAM 8GB) 6台で構成されている
    
カメラデバイスを装着したRaspberryPi（エッジデバイス）と、信号を受けて処理を行うRaspberryPi（ストリーミングサーバ）を分けていることがポイントです。エッジデバイスはあくまでカメラから得た情報をストリーミングサーバに配信し、ストリーミングサーバ側で処理・配信を行います。

## 構成について

以下のような構成・処理フローを考えました。  

![](/images/2021-10-12-r01/streaming.png)

データを送信するだけのエッジデバイスと、データの受信・処理・配信を担うストリーミングサーバで構成されます。ストリーミングサーバ内では、各工程に対してアプリケーション（Pod）が独立して稼働しており、サービス間で通信することでデータの処理や配信を実装することを考えました。

## エッジデバイス→ストリーミングサーバの通信について

カメラデバイスで取得し配信できるデータについて、カメラから取得できるデータは以下の2種類があります。

- コマ撮り画像
    - メリット: **データ通信量が少ない**
    - デメリット: 配信の際はデータの連結・変換・加工が必要
- 動画データ
    - メリット: データとして完成しているため、加工が不要 or シンプル
    - デメリット: **データの取得に負荷がかかる**・通信量が大幅に増加

今回はエッジデバイスは非常にスペックが低いことを想定し、RAWデータの内容はコマ撮り画像を用いることにしました。通信プロトコルについて、画像を送信するにあたり次の選択肢を考えました。

プロトコル | 説明
:-|:-
HTTP |一般的な通信プロトコル。同期処理・片方向通信。<br>クライアントのリクエストによりセッションの確立を行う。
FTP|ファイル転送プロトコル。同期処理・片方向通信。<br>2ポート使用するため、HTTPに比べ大きなファイル転送などに最適
AMQP|メッセージングプロトコル。非同期処理・双方向通信。<br>Producer(送信者)-MessageQue(キュー)-Consumer(受信者)間でセッションを確立。<br>高性能・高信頼。Openstackなどで利用されている。
MQTT|メッセージングプロトコル。非同期処理・双方向通信。<br>Client(受信者)-Broker(仲介)-Publisher(送信者)間でセッションを確立。<br>プロトコル自体が軽量で非常にオーバーヘッドが少ない、テキストデータしか送れない。

本開発ではカメラデータの送受信はMQTTが妥当だと判断しました。理由は以下です。  
- 同期処理では一つの通信が阻害された場合、他の通信が滞る可能性がある
    - エッジデバイスは低性能なため、ネットワーク障害は十分にあり得る
- データの送信機会が多く、1オペレーションのオーバーヘッドが少ない方がいい
    - 常にデータを送信し続けることがわかっているため、コネクションを切断する必要がない。

今回は上記を考慮し、MQTTを採用します。

## ストリーミングサーバ→クライアントの通信について

クライアントがストリーミングサーバに対して要求する要件は次の通りです。  
- Webブラウザ上で視聴可能であること
- 低遅延であること
- 低負荷であること

以上から、主要な動画の配信プロトコルの選択を行います。

プロトコル | 説明
-|-|-
RTP/RSTP|動画配信などに主に用いられていた。flashベースなためサポート終了
MPEG-DASH|ISO国際標準規格、ベンダーに依存しないが、iOSでは非対応とのこと
HLS|Apple社が開発している。IETFで承認され、現在youtubeなどの配信にも使われている

今回はクライアントの一部がiOSであること、広く使用されていることからHLSを選択します。

## HLSの仕組み  

HLSは、チャンクファイルという細切れで分断された動画ファイルと、チャンクファイルのリストで構成されます。  
クライアントはチャンクファイルのリストを参照し動画を読み込みます。  

このチャンクファイルのリストがHTML5クライアントにより随時更新され、新しいチャンクファイルを次々に参照することで、ライブストリーミングを実装しています。

細かな仕様については以下のブログが非常に参考になりました。  
https://did2memo.net/2017/02/20/http-live-streaming/  

# アプリケーションの開発

本システムの開発について考えていきます。  

## 


# 参考  

https://www.dpsj.co.jp/tech-articles/wowza-blog-hls  
https://qiita.com/wktq/items/a6e169e85a8a75c8524f  
http://happyking.blog47.fc2.com/blog-entry-58.html  
https://www.ydc.co.jp/column/0002/20170630.html  
https://tech-lab.sios.jp/archives/7902  
https://www.slideshare.net/terurou/mqttamqpnet
